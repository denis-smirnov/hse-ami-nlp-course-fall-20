{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"sem12-active-learning.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"iNokUVAV32ep"},"source":["## Active Learning"]},{"cell_type":"markdown","metadata":{"id":"cCFVOCmQ32e2"},"source":["Активное обучение $-$ класс алгоритмов обучения моделей машинного обучения. Алгоритмы активного обучения отличаются тем, что могут интерактивно запрашивать пользователя (или некоторый другой источник информации) для разметки новых примеров данных."]},{"cell_type":"markdown","metadata":{"id":"HT_bXK9w32fC"},"source":["<img src=\"active_learning.png\">"]},{"cell_type":"markdown","metadata":{"id":"IvkBh5pM32fM"},"source":["## Active Learning Strategies"]},{"cell_type":"markdown","metadata":{"id":"kQPJw4-r32fW"},"source":["#### Pool-Based Sampling"]},{"cell_type":"markdown","metadata":{"id":"xmsjB-U_32fd"},"source":["В этом сценарии экземпляры извлекаются из всего пула данных и им присваивается информативная оценка, которая показывает, насколько хорошо текущий алгоритм «понимает» данные. \n","\n","Затем системой выбираются и размечаются наиболее информативные примеры."]},{"cell_type":"markdown","metadata":{"id":"gl4YpbjY32fm"},"source":["#### Uncertainty sampling"]},{"cell_type":"markdown","metadata":{"id":"LlgrHIan32gW"},"source":["\n","В рамках этого алгоритма размечаются те примеры, в которых текущая модель наименее уверена.\n","\n","В качестве функций \"уверенности\" можно использовать вероятности классов или расстояния до разделяющей гиперплоскости."]},{"cell_type":"markdown","metadata":{"id":"8kxZcF0d32gf"},"source":["#### Membership Query Synthesis"]},{"cell_type":"markdown","metadata":{"id":"L_t9dcgQ32gk"},"source":["Здесь алгоритм обучения модели генерирует свои собственные примеры из некоторого настраиваемого распределения. \n","Эти сгенерированные примеры отправляются на разметку, и модель дообучается с учетом разметки этих примеров."]},{"cell_type":"markdown","metadata":{"id":"zXYx09By32gs"},"source":["#### Query by Committee"]},{"cell_type":"markdown","metadata":{"id":"h0cirVSc32gy"},"source":["Идея: построить ансамбль моделей $a_1,...,a_T$. \n","\n","Выбирать новые объекты $x_i$ с наибольшей несогласованностью решений ансамбля моделей.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cP1W6rSS32g4"},"source":["Принцип максимума энтропии: выбираем $x_i$, на котором $a_t(x_i)$ максимально различны."]},{"cell_type":"markdown","metadata":{"id":"i8auMfJW32hC"},"source":["Принцип максимума средней $KL$-дивергенции: выбираем $x_i$ , на котором $P_t(y|x_i)$ максимально различны.\n","\n","$С(y|u) = \\frac{1}{T}\\sum_{t=1}^T P_t(y|u)$ - консенсус комитета "]},{"cell_type":"markdown","metadata":{"id":"MqaocvIr32hM"},"source":["## SVM для Active Learning"]},{"cell_type":"markdown","metadata":{"id":"Pd4TtrJL32hR"},"source":["Некоторые активные алгоритмы обучения построены на алгоритме SVM и используют структуру SVM для определения того, какие точки данных нужно размечать. \n","\n","SVM используется для определения уверенности модели в предсказании на каждом из примеров выборки. \n","В качестве меры уверенности служит расстояние от объекта до построенной на текущей итерации разделяющей гиперплоскости."]},{"cell_type":"markdown","metadata":{"id":"2CmDD2V732hX"},"source":["## Active Learning for text classification"]},{"cell_type":"markdown","metadata":{"id":"WY5VOZyd32he"},"source":["Рассмотрим алгоритм pool-based active learning на примере задачи классификации твитов по тональности."]},{"cell_type":"markdown","metadata":{"id":"wnuTCe8v32hj"},"source":["\n","1. Разделить данные на X_pool (выборка, которую можно размечать) и X_test.\n","2. Выбрать $k$ примеров из X_pool для начального X_train и разметить их. Остальные данные в X_pool $-$ валидационное множество. \n","3. Обучить модель на  X_train.\n","5. Сделать predict обученной моделью на X_pool, вычислить вероятности для каждого $x_i$.\n","6. Вычислить качество работы модели на X_test.\n","7. Выбрать $k$ наиболее информативных объектов из X_pool, основываясь на уверенности модели в каждом из объектов (например, вероятности классов).\n","8. Переменести эти $k$ выбранных объектов в X_train.\n","9. Если качество работы модели на X_test достаточное, то останавливаемся, иначе возвращаемся к шагу 3."]},{"cell_type":"code","metadata":{"id":"fMb1FbfC32hp","executionInfo":{"status":"ok","timestamp":1605904636841,"user_tz":-180,"elapsed":1612,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}}},"source":["from sklearn.metrics import f1_score"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xj1dQ0hd32iQ","executionInfo":{"status":"ok","timestamp":1605904712382,"user_tz":-180,"elapsed":822,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import *\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from nltk import ngrams\n","\n","from sklearn.linear_model import LogisticRegression \n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIDQlwyy32it","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1605904860954,"user_tz":-180,"elapsed":1307,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}},"outputId":"d71ac70c-7453-4d69-96a6-2b03d5f01f12"},"source":["df = pd.read_csv('/content/sample_data/spam_text_classification_data.csv')\n","print(df.shape)\n","df.head()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(5572, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Category</th>\n","      <th>Message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Category                                            Message\n","0      ham  Go until jurong point, crazy.. Available only ...\n","1      ham                      Ok lar... Joking wif u oni...\n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      ham  U dun say so early hor... U c already then say...\n","4      ham  Nah I don't think he goes to usf, he lives aro..."]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"AJwOSCvw32jS","executionInfo":{"status":"ok","timestamp":1605904875089,"user_tz":-180,"elapsed":1084,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}}},"source":["df['label'] = [0 if category == 'ham' else 1 for category in df['Category']]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCwjMVZP32jq","executionInfo":{"status":"ok","timestamp":1605904877118,"user_tz":-180,"elapsed":945,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}}},"source":["X,X_test,y,y_test = train_test_split(np.array(df['Message']), np.array(df['label']))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VrAxpM832kG","executionInfo":{"status":"ok","timestamp":1605904879979,"user_tz":-180,"elapsed":1065,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}}},"source":["def get_confidence(class_probs):\n","    return abs(0.5-class_probs[0])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZS2rviJ32kg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605905148321,"user_tz":-180,"elapsed":266064,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}},"outputId":"6e38d325-af31-4d82-b330-dcfb4c53ee53"},"source":["train_size = 50\n","\n","dataset_size = X.shape[0]\n","target_score = 0.95\n","score = 0\n","step = 10\n","\n","X_train = X[:train_size]\n","y_train = y[:train_size]\n","X_pool = X[train_size:]\n","y_pool = y[train_size:]\n","\n","scores = [0]\n","train_szs = [0]\n","\n","while score < target_score and train_size <= dataset_size:\n","    vec = CountVectorizer(ngram_range=(1, 3))\n","    bow = vec.fit_transform(X_train)\n","    clf = LogisticRegression()\n","    clf = clf.fit(bow,y_train)\n","    pred = clf.predict(vec.transform(X_test))\n","    \n","    print(\"{0} train samples\".format(train_size))\n","    print(classification_report(pred, y_test))\n","    score = f1_score(pred, y_test)\n","    scores.append(score)\n","    train_szs.append(train_size)\n","    \n","    pred_probs = clf.predict_proba(vec.transform(X_pool))\n","    confidences = [get_confidence(probs) for probs in pred_probs]\n","    \n","    X_train = np.concatenate([X_train, X_pool[np.argsort(confidences)[:step]]])\n","    y_train = np.concatenate([y_train, y_pool[np.argsort(confidences)[:step]]])\n","    X_pool = X_pool[sorted(np.argsort(confidences)[step:])]\n","    y_pool = y_pool[sorted(np.argsort(confidences)[step:])]\n","    train_size += step"],"execution_count":9,"outputs":[{"output_type":"stream","text":["50 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.87      0.93      1391\n","           1       0.01      1.00      0.02         2\n","\n","    accuracy                           0.87      1393\n","   macro avg       0.51      0.93      0.47      1393\n","weighted avg       1.00      0.87      0.93      1393\n","\n","60 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.87      0.93      1384\n","           1       0.05      1.00      0.09         9\n","\n","    accuracy                           0.87      1393\n","   macro avg       0.52      0.94      0.51      1393\n","weighted avg       0.99      0.87      0.93      1393\n","\n","70 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.87      0.93      1378\n","           1       0.08      1.00      0.15        15\n","\n","    accuracy                           0.88      1393\n","   macro avg       0.54      0.94      0.54      1393\n","weighted avg       0.99      0.88      0.92      1393\n","\n","80 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.89      0.94      1352\n","           1       0.20      0.93      0.33        41\n","\n","    accuracy                           0.89      1393\n","   macro avg       0.60      0.91      0.64      1393\n","weighted avg       0.97      0.89      0.92      1393\n","\n","90 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.90      0.95      1329\n","           1       0.31      0.92      0.47        64\n","\n","    accuracy                           0.90      1393\n","   macro avg       0.65      0.91      0.71      1393\n","weighted avg       0.96      0.90      0.93      1393\n","\n","100 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.91      0.95      1320\n","           1       0.37      0.96      0.54        73\n","\n","    accuracy                           0.91      1393\n","   macro avg       0.68      0.93      0.74      1393\n","weighted avg       0.96      0.91      0.93      1393\n","\n","110 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.93      0.96      1286\n","           1       0.54      0.94      0.68       107\n","\n","    accuracy                           0.93      1393\n","   macro avg       0.77      0.94      0.82      1393\n","weighted avg       0.96      0.93      0.94      1393\n","\n","120 train samples\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.94      0.97      1269\n","           1       0.62      0.94      0.75       124\n","\n","    accuracy                           0.94      1393\n","   macro avg       0.81      0.94      0.86      1393\n","weighted avg       0.96      0.94      0.95      1393\n","\n","130 train samples\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.96      0.97      1248\n","           1       0.71      0.92      0.80       145\n","\n","    accuracy                           0.95      1393\n","   macro avg       0.85      0.94      0.89      1393\n","weighted avg       0.96      0.95      0.95      1393\n","\n","140 train samples\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.96      0.97      1249\n","           1       0.70      0.92      0.80       144\n","\n","    accuracy                           0.95      1393\n","   macro avg       0.85      0.94      0.88      1393\n","weighted avg       0.96      0.95      0.95      1393\n","\n","150 train samples\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.96      0.98      1247\n","           1       0.73      0.95      0.83       146\n","\n","    accuracy                           0.96      1393\n","   macro avg       0.86      0.95      0.90      1393\n","weighted avg       0.97      0.96      0.96      1393\n","\n","160 train samples\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.96      0.98      1244\n","           1       0.75      0.95      0.84       149\n","\n","    accuracy                           0.96      1393\n","   macro avg       0.87      0.95      0.91      1393\n","weighted avg       0.97      0.96      0.96      1393\n","\n","170 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98      1246\n","           1       0.75      0.96      0.84       147\n","\n","    accuracy                           0.96      1393\n","   macro avg       0.87      0.96      0.91      1393\n","weighted avg       0.97      0.96      0.96      1393\n","\n","180 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98      1242\n","           1       0.77      0.96      0.86       151\n","\n","    accuracy                           0.96      1393\n","   macro avg       0.88      0.96      0.92      1393\n","weighted avg       0.97      0.96      0.97      1393\n","\n","190 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98      1241\n","           1       0.78      0.96      0.86       152\n","\n","    accuracy                           0.97      1393\n","   macro avg       0.89      0.96      0.92      1393\n","weighted avg       0.97      0.97      0.97      1393\n","\n","200 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98      1241\n","           1       0.78      0.97      0.86       152\n","\n","    accuracy                           0.97      1393\n","   macro avg       0.89      0.97      0.92      1393\n","weighted avg       0.97      0.97      0.97      1393\n","\n","210 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98      1235\n","           1       0.81      0.97      0.88       158\n","\n","    accuracy                           0.97      1393\n","   macro avg       0.90      0.97      0.93      1393\n","weighted avg       0.98      0.97      0.97      1393\n","\n","220 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1227\n","           1       0.86      0.97      0.91       166\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.97      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","230 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1222\n","           1       0.88      0.97      0.92       171\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","240 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1226\n","           1       0.87      0.98      0.92       167\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.98      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","250 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1223\n","           1       0.88      0.98      0.93       170\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","260 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1221\n","           1       0.89      0.98      0.93       172\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.95      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","270 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1224\n","           1       0.88      0.98      0.93       169\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","280 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1225\n","           1       0.88      0.98      0.93       168\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","290 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1224\n","           1       0.88      0.98      0.93       169\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","300 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1225\n","           1       0.88      0.98      0.93       168\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.98      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","310 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1225\n","           1       0.89      0.99      0.94       168\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.99      0.98      0.98      1393\n","\n","320 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1224\n","           1       0.89      0.99      0.94       169\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.95      0.99      0.97      1393\n","weighted avg       0.99      0.98      0.99      1393\n","\n","330 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1225\n","           1       0.89      1.00      0.94       168\n","\n","    accuracy                           0.99      1393\n","   macro avg       0.95      0.99      0.97      1393\n","weighted avg       0.99      0.99      0.99      1393\n","\n","340 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1226\n","           1       0.89      1.00      0.94       167\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.97      1393\n","weighted avg       0.99      0.98      0.99      1393\n","\n","350 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1228\n","           1       0.88      1.00      0.93       165\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.99      0.98      0.98      1393\n","\n","360 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1227\n","           1       0.88      1.00      0.94       166\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.99      0.98      0.98      1393\n","\n","370 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1228\n","           1       0.88      1.00      0.93       165\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.99      0.98      0.98      1393\n","\n","380 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1227\n","           1       0.88      1.00      0.94       166\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.99      0.98      0.98      1393\n","\n","390 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1229\n","           1       0.87      1.00      0.93       164\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","400 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1229\n","           1       0.87      1.00      0.93       164\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","410 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","420 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1229\n","           1       0.87      1.00      0.93       164\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","430 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","440 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","450 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","460 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","470 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","480 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","490 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","500 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1228\n","           1       0.88      1.00      0.93       165\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.99      0.98      0.98      1393\n","\n","510 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1229\n","           1       0.87      1.00      0.93       164\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.94      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","520 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","530 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","540 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","550 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","560 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","570 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","580 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","590 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1230\n","           1       0.87      1.00      0.93       163\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","600 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","610 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","620 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","630 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","640 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","650 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","660 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","670 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","680 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","690 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","700 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1231\n","           1       0.86      1.00      0.93       162\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","710 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","720 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","730 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","740 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","750 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","760 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","770 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","780 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","790 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","800 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","810 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","820 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","830 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","840 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","850 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","860 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","870 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","880 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","890 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","900 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","910 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","920 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","930 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","940 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","950 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","960 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","970 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","980 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","990 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1000 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1010 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1020 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1030 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1040 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1050 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1060 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1070 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1080 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1090 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1100 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1110 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1120 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1130 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1140 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1150 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1160 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1170 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1180 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1190 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1200 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1210 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1220 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1230 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1240 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1250 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1260 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1270 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1280 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1290 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1300 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1310 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1320 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1234\n","           1       0.85      1.00      0.92       159\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.92      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1330 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1340 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1350 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1360 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1370 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1380 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1390 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1400 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1410 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1420 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1430 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1440 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1450 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1460 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1470 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1480 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1490 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1500 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1510 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1520 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1530 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1540 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1550 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1560 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1570 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1580 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1590 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1600 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1610 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1620 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1630 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1640 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1650 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1660 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1670 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1680 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1690 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1700 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1710 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1720 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1730 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1740 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1750 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1760 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1770 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1780 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1790 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1800 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1810 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1820 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1830 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1840 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1850 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1860 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1870 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1880 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1890 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1900 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1910 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1920 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1930 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1940 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1950 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1960 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1970 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1980 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","1990 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2000 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2010 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2020 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2030 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2040 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2050 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2060 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2070 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2080 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2090 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2100 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2110 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2120 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2130 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2140 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2150 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2160 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2170 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2180 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2190 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2200 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2210 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2220 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2230 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2240 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2250 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2260 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2270 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2280 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2290 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2300 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2310 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2320 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2330 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2340 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2350 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2360 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2370 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2380 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2390 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2400 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2410 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2420 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2430 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2440 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2450 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2460 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2470 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2480 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2490 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2500 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2510 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2520 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2530 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2540 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2550 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2560 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2570 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2580 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2590 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2600 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2610 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2620 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2630 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2640 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2650 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2660 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2670 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2680 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2690 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2700 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2710 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2720 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2730 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2740 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2750 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2760 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2770 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2780 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2790 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2800 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2810 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2820 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2830 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2840 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2850 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2860 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2870 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2880 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2890 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2900 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2910 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2920 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2930 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2940 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2950 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2960 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2970 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2980 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","2990 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3000 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3010 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3020 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3030 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3040 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3050 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3060 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3070 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3080 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3090 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3100 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3110 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3120 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3130 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3140 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3150 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3160 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3170 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3180 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3190 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3200 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3210 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3220 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3230 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3240 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3250 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3260 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3270 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3280 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3290 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3300 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3310 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3320 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3330 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3340 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3350 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3360 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3370 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3380 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3390 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3400 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3410 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3420 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3430 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3440 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3450 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3460 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3470 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3480 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3490 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3500 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3510 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3520 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3530 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3540 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3550 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3560 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3570 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3580 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3590 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3600 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3610 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3620 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3630 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3640 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3650 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3660 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3670 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3680 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3690 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3700 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3710 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3720 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3730 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3740 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3750 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3760 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3770 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3780 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3790 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3800 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3810 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3820 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3830 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3840 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3850 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3860 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3870 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3880 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3890 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3900 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3910 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3920 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3930 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3940 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3950 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3960 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3970 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3980 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","3990 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4000 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4010 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4020 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4030 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4040 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4050 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4060 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4070 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4080 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4090 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4100 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4110 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4120 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4130 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4140 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4150 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4160 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n","4170 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1233\n","           1       0.85      1.00      0.92       160\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.95      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ayVvb1LJ32k9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605905161158,"user_tz":-180,"elapsed":1204,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}},"outputId":"4b495e26-60fb-460f-be26-219a296d524f"},"source":["vec = CountVectorizer(ngram_range=(1, 2))\n","bow = vec.fit_transform(X)\n","clf = clf.fit(bow,y)\n","pred = clf.predict(vec.transform(X_test))\n","\n","print(\"{0} train samples\".format(dataset_size))\n","print(classification_report(pred, y_test))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["4179 train samples\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1232\n","           1       0.86      1.00      0.92       161\n","\n","    accuracy                           0.98      1393\n","   macro avg       0.93      0.99      0.96      1393\n","weighted avg       0.98      0.98      0.98      1393\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q050fdZQ32lY","executionInfo":{"status":"ok","timestamp":1605905177382,"user_tz":-180,"elapsed":902,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}}},"source":["from matplotlib import pyplot as plt\n","\n","%matplotlib inline"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dwzb2qK232l0","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1605905179245,"user_tz":-180,"elapsed":826,"user":{"displayName":"Dmitry Ilvovsky","photoUrl":"","userId":"04607260023147477501"}},"outputId":"5df1aed2-b966-4c22-bcf0-c66a8c089685"},"source":["plt.plot(train_szs,scores)\n","plt.plot(train_szs, [0.95 for sz in train_szs])"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f513e095d68>]"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"qzYzp4v432mJ"},"source":["Можно видеть, что для достижения лучшего качества на этом датасете достаточно обучиться на 300 правильно выбранных примерах."]},{"cell_type":"code","metadata":{"id":"rypVhC0932mM"},"source":[""],"execution_count":null,"outputs":[]}]}